{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b68581d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Tutorial 참조\n",
    "#https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2eb22540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de24e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "237fa235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import csv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a6ae4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7efe518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "ts=pd.read_csv(\"Features_testset.csv\")\n",
    "tv=pd.read_csv(\"Features_trainvalidation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ec7e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv['Bandgap'] = np.where(tv['Bandgap']== 0,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "458e4320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35906\n",
       "1     8268\n",
       "Name: Bandgap, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv['Bandgap'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b1d8615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NComp</th>\n",
       "      <th>Comp_L2Norm</th>\n",
       "      <th>Comp_L3Norm</th>\n",
       "      <th>Comp_L5Norm</th>\n",
       "      <th>Comp_L7Norm</th>\n",
       "      <th>Comp_L10Norm</th>\n",
       "      <th>mean_Number</th>\n",
       "      <th>maxdiff_Number</th>\n",
       "      <th>dev_Number</th>\n",
       "      <th>max_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>frac_sValence</th>\n",
       "      <th>frac_pValence</th>\n",
       "      <th>frac_dValence</th>\n",
       "      <th>frac_fValence</th>\n",
       "      <th>CanFormIonic</th>\n",
       "      <th>MaxIonicChar</th>\n",
       "      <th>MeanIonicChar</th>\n",
       "      <th>Index</th>\n",
       "      <th>TotalEnergy</th>\n",
       "      <th>Bandgap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.4803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.2681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.5294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>13</td>\n",
       "      <td>-3.5643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>17</td>\n",
       "      <td>-3.4825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NComp  Comp_L2Norm  Comp_L3Norm  Comp_L5Norm  Comp_L7Norm  Comp_L10Norm  \\\n",
       "0      1     1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "1      1     1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "2      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "3      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "4      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "\n",
       "   mean_Number  maxdiff_Number  dev_Number  max_Number  ...  frac_sValence  \\\n",
       "0    89.000000               0    0.000000          89  ...       0.666667   \n",
       "1    47.000000               0    0.000000          47  ...       0.090909   \n",
       "2    57.666667              32   14.222222          79  ...       0.063830   \n",
       "3    57.666667              32   14.222222          79  ...       0.063830   \n",
       "4    57.666667              32   14.222222          79  ...       0.063830   \n",
       "\n",
       "   frac_pValence  frac_dValence  frac_fValence  CanFormIonic  MaxIonicChar  \\\n",
       "0            0.0       0.333333       0.000000             0      0.000000   \n",
       "1            0.0       0.909091       0.000000             0      0.000000   \n",
       "2            0.0       0.638298       0.297872             0      0.088829   \n",
       "3            0.0       0.638298       0.297872             0      0.088829   \n",
       "4            0.0       0.638298       0.297872             0      0.088829   \n",
       "\n",
       "   MeanIonicChar  Index  TotalEnergy  Bandgap  \n",
       "0        0.00000      1      -4.4803        0  \n",
       "1        0.00000      5      -3.2681        0  \n",
       "2        0.03948      9      -3.5294        0  \n",
       "3        0.03948     13      -3.5643        0  \n",
       "4        0.03948     17      -3.4825        0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20d1638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bandgap                  1.000000\n",
       "CanFormIonic             0.691193\n",
       "mean_NpValence           0.640377\n",
       "frac_pValence            0.639319\n",
       "most_NpValence           0.614357\n",
       "max_NpValence            0.583238\n",
       "max_Electronegativity    0.576072\n",
       "maxdiff_NpValence        0.559717\n",
       "MaxIonicChar             0.553415\n",
       "MeanIonicChar            0.552481\n",
       "dev_NpValence            0.541735\n",
       "Name: Bandgap, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#상위 10개 상관관계 확인\n",
    "corr_matrix = tv.corr()\n",
    "\n",
    "df_corr_matrix = corr_matrix[\"Bandgap\"].sort_values(axis=0, ascending=False)\n",
    "df_corr_matrix.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56942498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_Number', 'min_Number', 'most_Number', 'mean_AtomicWeight', 'min_AtomicWeight', 'most_AtomicWeight', 'mean_MeltingT', 'min_MeltingT', 'most_MeltingT', 'mean_Row', 'min_Row', 'most_Row', 'mean_CovalentRadius', 'min_CovalentRadius', 'most_CovalentRadius', 'mean_NdValence', 'most_NdValence', 'mean_NfValence', 'most_NfValence', 'mean_NdUnfilled', 'most_NdUnfilled', 'mean_NUnfilled', 'most_NUnfilled', 'mean_SpaceGroupNumber', 'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_dValence', 'frac_fValence']\n"
     ]
    }
   ],
   "source": [
    "# 상관관계가 -0.2 미만 0.2 초과인 피쳐 확인\n",
    "\n",
    "corr_matrix_2 = pd.DataFrame(corr_matrix.iloc[-1,:]).T\n",
    "\n",
    "throw_away_col = []\n",
    "for col in corr_matrix_2:\n",
    "    if abs(-0.2 <= corr_matrix_2[col][0]) <= 0.2:\n",
    "        throw_away_col.append(col)\n",
    "print(throw_away_col)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea3a90e9",
   "metadata": {},
   "source": [
    "#피처 삭제\n",
    "tv.drop(['mean_Number', 'min_Number', 'most_Number', 'mean_AtomicWeight', 'min_AtomicWeight', 'most_AtomicWeight', 'mean_MeltingT', 'min_MeltingT', 'most_MeltingT', 'mean_Row', 'min_Row', 'most_Row', 'mean_CovalentRadius', 'min_CovalentRadius', 'most_CovalentRadius', 'mean_NdValence', 'most_NdValence', 'mean_NfValence', 'most_NfValence', 'mean_NdUnfilled', 'most_NdUnfilled', 'mean_NUnfilled', 'most_NUnfilled', 'mean_SpaceGroupNumber', 'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_dValence', 'frac_fValence]\n",
    "              , axis = 1, inplace = True)\n",
    "\n",
    "tv.drop(['mean_Number', 'min_Number', 'most_Number', 'mean_AtomicWeight', 'min_AtomicWeight', 'most_AtomicWeight', 'mean_MeltingT', 'min_MeltingT', 'most_MeltingT', 'mean_Row', 'min_Row', 'most_Row', 'mean_CovalentRadius', 'min_CovalentRadius', 'most_CovalentRadius', 'mean_NdValence', 'max_NdValence', 'most_NdValence', 'mean_NValance', 'mean_NdUnfilled', 'mean_NUnfilled', 'most_NUnfilled', 'mean_SpaceGroupNumber', 'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_dValence']\n",
    "              , axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b326b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44174, 148)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6aa3e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44174 entries, 0 to 44173\n",
      "Columns: 148 entries, NComp to Bandgap\n",
      "dtypes: float64(96), int32(1), int64(51)\n",
      "memory usage: 49.7 MB\n"
     ]
    }
   ],
   "source": [
    "tv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6be14a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NComp</th>\n",
       "      <th>Comp_L2Norm</th>\n",
       "      <th>Comp_L3Norm</th>\n",
       "      <th>Comp_L5Norm</th>\n",
       "      <th>Comp_L7Norm</th>\n",
       "      <th>Comp_L10Norm</th>\n",
       "      <th>mean_Number</th>\n",
       "      <th>maxdiff_Number</th>\n",
       "      <th>dev_Number</th>\n",
       "      <th>max_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>frac_sValence</th>\n",
       "      <th>frac_pValence</th>\n",
       "      <th>frac_dValence</th>\n",
       "      <th>frac_fValence</th>\n",
       "      <th>CanFormIonic</th>\n",
       "      <th>MaxIonicChar</th>\n",
       "      <th>MeanIonicChar</th>\n",
       "      <th>Index</th>\n",
       "      <th>TotalEnergy</th>\n",
       "      <th>Bandgap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.4803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.2681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.5294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>13</td>\n",
       "      <td>-3.5643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.693361</td>\n",
       "      <td>0.670782</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>0.666732</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>32</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088829</td>\n",
       "      <td>0.03948</td>\n",
       "      <td>17</td>\n",
       "      <td>-3.4825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NComp  Comp_L2Norm  Comp_L3Norm  Comp_L5Norm  Comp_L7Norm  Comp_L10Norm  \\\n",
       "0      1     1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "1      1     1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "2      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "3      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "4      2     0.745356     0.693361     0.670782     0.667408      0.666732   \n",
       "\n",
       "   mean_Number  maxdiff_Number  dev_Number  max_Number  ...  frac_sValence  \\\n",
       "0    89.000000               0    0.000000          89  ...       0.666667   \n",
       "1    47.000000               0    0.000000          47  ...       0.090909   \n",
       "2    57.666667              32   14.222222          79  ...       0.063830   \n",
       "3    57.666667              32   14.222222          79  ...       0.063830   \n",
       "4    57.666667              32   14.222222          79  ...       0.063830   \n",
       "\n",
       "   frac_pValence  frac_dValence  frac_fValence  CanFormIonic  MaxIonicChar  \\\n",
       "0            0.0       0.333333       0.000000             0      0.000000   \n",
       "1            0.0       0.909091       0.000000             0      0.000000   \n",
       "2            0.0       0.638298       0.297872             0      0.088829   \n",
       "3            0.0       0.638298       0.297872             0      0.088829   \n",
       "4            0.0       0.638298       0.297872             0      0.088829   \n",
       "\n",
       "   MeanIonicChar  Index  TotalEnergy  Bandgap  \n",
       "0        0.00000      1      -4.4803        0  \n",
       "1        0.00000      5      -3.2681        0  \n",
       "2        0.03948      9      -3.5294        0  \n",
       "3        0.03948     13      -3.5643        0  \n",
       "4        0.03948     17      -3.4825        0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68b73917",
   "metadata": {},
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88117af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44174, 148)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(tv)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdaed1",
   "metadata": {},
   "source": [
    "# Keras Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87138ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28271 train examples\n",
      "7068 validation examples\n",
      "8835 test examples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(tv, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cce4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Bandgap')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ff3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a628e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['NComp', 'Comp_L2Norm', 'Comp_L3Norm', 'Comp_L5Norm', 'Comp_L7Norm', 'Comp_L10Norm', 'mean_Number', 'maxdiff_Number', 'dev_Number', 'max_Number', 'min_Number', 'most_Number', 'mean_MendeleevNumber', 'maxdiff_MendeleevNumber', 'dev_MendeleevNumber', 'max_MendeleevNumber', 'min_MendeleevNumber', 'most_MendeleevNumber', 'mean_AtomicWeight', 'maxdiff_AtomicWeight', 'dev_AtomicWeight', 'max_AtomicWeight', 'min_AtomicWeight', 'most_AtomicWeight', 'mean_MeltingT', 'maxdiff_MeltingT', 'dev_MeltingT', 'max_MeltingT', 'min_MeltingT', 'most_MeltingT', 'mean_Column', 'maxdiff_Column', 'dev_Column', 'max_Column', 'min_Column', 'most_Column', 'mean_Row', 'maxdiff_Row', 'dev_Row', 'max_Row', 'min_Row', 'most_Row', 'mean_CovalentRadius', 'maxdiff_CovalentRadius', 'dev_CovalentRadius', 'max_CovalentRadius', 'min_CovalentRadius', 'most_CovalentRadius', 'mean_Electronegativity', 'maxdiff_Electronegativity', 'dev_Electronegativity', 'max_Electronegativity', 'min_Electronegativity', 'most_Electronegativity', 'mean_NsValence', 'maxdiff_NsValence', 'dev_NsValence', 'max_NsValence', 'min_NsValence', 'most_NsValence', 'mean_NpValence', 'maxdiff_NpValence', 'dev_NpValence', 'max_NpValence', 'min_NpValence', 'most_NpValence', 'mean_NdValence', 'maxdiff_NdValence', 'dev_NdValence', 'max_NdValence', 'min_NdValence', 'most_NdValence', 'mean_NfValence', 'maxdiff_NfValence', 'dev_NfValence', 'max_NfValence', 'min_NfValence', 'most_NfValence', 'mean_NValance', 'maxdiff_NValance', 'dev_NValance', 'max_NValance', 'min_NValance', 'most_NValance', 'mean_NsUnfilled', 'maxdiff_NsUnfilled', 'dev_NsUnfilled', 'max_NsUnfilled', 'min_NsUnfilled', 'most_NsUnfilled', 'mean_NpUnfilled', 'maxdiff_NpUnfilled', 'dev_NpUnfilled', 'max_NpUnfilled', 'min_NpUnfilled', 'most_NpUnfilled', 'mean_NdUnfilled', 'maxdiff_NdUnfilled', 'dev_NdUnfilled', 'max_NdUnfilled', 'min_NdUnfilled', 'most_NdUnfilled', 'mean_NfUnfilled', 'maxdiff_NfUnfilled', 'dev_NfUnfilled', 'max_NfUnfilled', 'min_NfUnfilled', 'most_NfUnfilled', 'mean_NUnfilled', 'maxdiff_NUnfilled', 'dev_NUnfilled', 'max_NUnfilled', 'min_NUnfilled', 'most_NUnfilled', 'mean_GSvolume_pa', 'maxdiff_GSvolume_pa', 'dev_GSvolume_pa', 'max_GSvolume_pa', 'min_GSvolume_pa', 'most_GSvolume_pa', 'mean_GSbandgap', 'maxdiff_GSbandgap', 'dev_GSbandgap', 'max_GSbandgap', 'min_GSbandgap', 'most_GSbandgap', 'mean_GSmagmom', 'maxdiff_GSmagmom', 'dev_GSmagmom', 'max_GSmagmom', 'min_GSmagmom', 'most_GSmagmom', 'mean_SpaceGroupNumber', 'maxdiff_SpaceGroupNumber', 'dev_SpaceGroupNumber', 'max_SpaceGroupNumber', 'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_sValence', 'frac_pValence', 'frac_dValence', 'frac_fValence', 'CanFormIonic', 'MaxIonicChar', 'MeanIonicChar', 'Index', 'TotalEnergy']\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff4163",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fdddf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e1630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.13652618, 0.13652618, 0.13652618, 0.13652618, 0.13652618],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_count_col = train_features['NComp']\n",
    "layer = get_normalization_layer('NComp', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "602314a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용할 열 선택\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3afd3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['NComp', 'Comp_L2Norm', 'Comp_L3Norm', 'Comp_L5Norm', 'Comp_L7Norm', 'Comp_L10Norm', 'mean_Number', 'maxdiff_Number', \n",
    "               'dev_Number', 'max_Number', 'min_Number', 'most_Number', 'mean_MendeleevNumber', 'maxdiff_MendeleevNumber', \n",
    "               'dev_MendeleevNumber', 'max_MendeleevNumber', 'min_MendeleevNumber', 'most_MendeleevNumber', 'mean_AtomicWeight', \n",
    "               'maxdiff_AtomicWeight', 'dev_AtomicWeight', 'max_AtomicWeight', 'min_AtomicWeight', 'most_AtomicWeight', \n",
    "               'mean_MeltingT', 'maxdiff_MeltingT', 'dev_MeltingT', 'max_MeltingT', 'min_MeltingT', 'most_MeltingT', 'mean_Column', \n",
    "               'maxdiff_Column', 'dev_Column', 'max_Column', 'min_Column', 'most_Column', 'mean_Row', 'maxdiff_Row', 'dev_Row', \n",
    "               'max_Row', 'min_Row', 'most_Row', 'mean_CovalentRadius', 'maxdiff_CovalentRadius', 'dev_CovalentRadius', \n",
    "               'max_CovalentRadius', 'min_CovalentRadius', 'most_CovalentRadius', 'mean_Electronegativity', \n",
    "               'maxdiff_Electronegativity', 'dev_Electronegativity', 'max_Electronegativity', 'min_Electronegativity', \n",
    "               'most_Electronegativity', 'mean_NsValence', 'maxdiff_NsValence', 'dev_NsValence', 'max_NsValence', \n",
    "               'min_NsValence', 'most_NsValence', 'mean_NpValence', 'maxdiff_NpValence', 'dev_NpValence', 'max_NpValence', \n",
    "               'min_NpValence', 'most_NpValence', 'mean_NdValence', 'maxdiff_NdValence', 'dev_NdValence', 'max_NdValence', \n",
    "               'min_NdValence', 'most_NdValence', 'mean_NfValence', 'maxdiff_NfValence', 'dev_NfValence', 'max_NfValence', \n",
    "               'min_NfValence', 'most_NfValence', 'mean_NValance', 'maxdiff_NValance', 'dev_NValance', 'max_NValance', \n",
    "               'min_NValance', 'most_NValance', 'mean_NsUnfilled', 'maxdiff_NsUnfilled', 'dev_NsUnfilled', 'max_NsUnfilled',\n",
    "               'min_NsUnfilled', 'most_NsUnfilled', 'mean_NpUnfilled', 'maxdiff_NpUnfilled', 'dev_NpUnfilled', 'max_NpUnfilled',\n",
    "               'min_NpUnfilled', 'most_NpUnfilled', 'mean_NdUnfilled', 'maxdiff_NdUnfilled', 'dev_NdUnfilled', 'max_NdUnfilled', \n",
    "               'min_NdUnfilled', 'most_NdUnfilled', 'mean_NfUnfilled', 'maxdiff_NfUnfilled', 'dev_NfUnfilled', 'max_NfUnfilled', \n",
    "               'min_NfUnfilled', 'most_NfUnfilled', 'mean_NUnfilled', 'maxdiff_NUnfilled', 'dev_NUnfilled', 'max_NUnfilled', \n",
    "               'min_NUnfilled', 'most_NUnfilled', 'mean_GSvolume_pa', 'maxdiff_GSvolume_pa', 'dev_GSvolume_pa', 'max_GSvolume_pa', \n",
    "               'min_GSvolume_pa', 'most_GSvolume_pa', 'mean_GSbandgap', 'maxdiff_GSbandgap', 'dev_GSbandgap', 'max_GSbandgap', \n",
    "               'min_GSbandgap', 'most_GSbandgap', 'mean_GSmagmom', 'maxdiff_GSmagmom', 'dev_GSmagmom', 'max_GSmagmom', \n",
    "               'min_GSmagmom', 'most_GSmagmom', 'mean_SpaceGroupNumber', 'maxdiff_SpaceGroupNumber', 'dev_SpaceGroupNumber', \n",
    "               'max_SpaceGroupNumber', 'min_SpaceGroupNumber', 'most_SpaceGroupNumber', 'frac_sValence', 'frac_pValence', \n",
    "               'frac_dValence', 'frac_fValence', 'CanFormIonic', 'MaxIonicChar', 'MeanIonicChar']:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14bc4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ee3d186",
   "metadata": {},
   "source": [
    "# rankdir='LR' is used to make the graph horizontal.\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589c3a2",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63181092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:559: UserWarning: Input dict contained keys ['Index', 'TotalEnergy'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 5s 23ms/step - loss: 0.3948 - accuracy: 0.8379 - val_loss: 0.2323 - val_accuracy: 0.8977\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.2339 - accuracy: 0.8988 - val_loss: 0.2130 - val_accuracy: 0.9012\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.2151 - accuracy: 0.9065 - val_loss: 0.2036 - val_accuracy: 0.9131\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.2036 - accuracy: 0.9136 - val_loss: 0.1990 - val_accuracy: 0.9144\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.1986 - accuracy: 0.9160 - val_loss: 0.1943 - val_accuracy: 0.9182\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.1938 - accuracy: 0.9186 - val_loss: 0.1908 - val_accuracy: 0.9211\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 3s 15ms/step - loss: 0.1896 - accuracy: 0.9173 - val_loss: 0.1902 - val_accuracy: 0.9215\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 3s 15ms/step - loss: 0.1900 - accuracy: 0.9197 - val_loss: 0.1872 - val_accuracy: 0.9208\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.1856 - accuracy: 0.9211 - val_loss: 0.1860 - val_accuracy: 0.9196\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 3s 16ms/step - loss: 0.1837 - accuracy: 0.9211 - val_loss: 0.1867 - val_accuracy: 0.9236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14883076bb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c98fc950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 13ms/step - loss: 0.1722 - accuracy: 0.9288\n",
      "Accuracy 0.9288058876991272\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597c012",
   "metadata": {},
   "source": [
    "# 모델 검증"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cde9a309",
   "metadata": {},
   "source": [
    "#precision, recall, f1_score\n",
    "from keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score\n",
    "\n",
    "#https://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221226716255"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6159adb",
   "metadata": {},
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "                 ,loss=tf.keras.losses.binary_crossentropy\n",
    "                 ,metrics=[tf.keras.metrics.Precision(name='precision')\\\n",
    "                          ,tf.keras.metrics.Recall(name='recall')\\\n",
    "                          ,tf.keras.metrics.FalsePositives(name='false_positives')\\\n",
    "                          ,tf.keras.metrics.FalseNegatives(name='false_negatives')])\n",
    "\n",
    "#https://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221226716255"
   ]
  },
  {
   "cell_type": "raw",
   "id": "645da8ff",
   "metadata": {},
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(train, test, validation_split=0.3, epochs=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(Xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fcb4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.drop(['Index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b09b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06187a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce9ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba897888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840cb9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48a35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163f887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852ea64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13104e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
